@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lan2020albert,
      title={ALBERT: A Lite BERT for Self-supervised Learning of Language Representations}, 
      author={Zhenzhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
      year={2020},
      eprint={1909.11942},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tambe2021edgebert,
      title={EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference}, 
      author={Thierry Tambe and Coleman Hooper and Lillian Pentecost and Tianyu Jia and En-Yu Yang and Marco Donato and Victor Sanh and Paul N. Whatmough and Alexander M. Rush and David Brooks and Gu-Yeon Wei},
      year={2021},
      eprint={2011.14203},
      archivePrefix={arXiv},
      primaryClass={cs.AR}
}
